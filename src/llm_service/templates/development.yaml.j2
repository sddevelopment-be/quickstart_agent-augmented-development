# Development Configuration Template
# All features enabled with debug logging for testing and development

# Service Configuration
service:
  name: "llm-service-development"
  version: "1.0.0"
  log_level: "DEBUG"

# Agent Configurations
agents:
  test-agent:
    preferred_tool: "mock-tool"
    preferred_model: "mock-model"
    fallback_chain:
      - "mock-tool:mock-model-fallback"
    task_types:
      test: "mock-model"
      dev: "mock-model"

  claude-agent:
    preferred_tool: "claude-code"
    preferred_model: "claude-3.5-sonnet"
    fallback_chain:
      - "claude-code:claude-3-haiku"
    task_types:
      simple: "claude-3-haiku"
      complex: "claude-3.5-sonnet"

  multi-tool-agent:
    preferred_tool: "openai"
    preferred_model: "gpt-4o-mini"
    fallback_chain:
      - "openai:gpt-4o"
      - "claude-code:claude-3-haiku"
    task_types: {}

# Tool Configurations
tools:
  # Mock tool for testing
  mock-tool:
    binary: "echo"
    command_template: "{binary} 'Mock response for model {model}' > {output_file}"
    models:
      - "mock-model"
      - "mock-model-fallback"
    capabilities:
      - "testing"
      - "development"
    env_vars: {}
    env_required: []

  # Real tools with flexible paths
  claude-code:
    binary: "{{ claude_binary|default('claude') }}"
    command_template: "{binary} --model {model} < {prompt_file}"
    models:
      - "claude-3.5-sonnet"
      - "claude-3-opus"
      - "claude-3-haiku"
    capabilities:
      - "code_generation"
      - "code_review"
      - "general_qa"
    env_vars:
      ANTHROPIC_API_KEY: "${ANTHROPIC_API_KEY}"
    env_required:
      - "ANTHROPIC_API_KEY"
    platforms:
      linux: "/usr/local/bin/claude"
      macos: "/usr/local/bin/claude"
      windows: "C:\\Program Files\\Claude\\claude.exe"

  openai:
    binary: "{{ openai_binary|default('openai') }}"
    command_template: "{binary} --model {model} --input {prompt_file}"
    models:
      - "gpt-4o"
      - "gpt-4o-mini"
      - "gpt-4-turbo"
    capabilities:
      - "code_generation"
      - "analysis"
    env_vars:
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
    env_required:
      - "OPENAI_API_KEY"
    platforms:
      linux: "/usr/local/bin/openai"
      macos: "/usr/local/bin/openai"
      windows: "C:\\Program Files\\OpenAI\\openai.exe"

# Model Configurations
models:
  # Mock models for testing
  mock-model:
    provider: "mock"
    cost_per_1k_tokens:
      input: 0.0
      output: 0.0
    context_window: 100000
    task_suitability:
      - "test"
      - "dev"
  
  mock-model-fallback:
    provider: "mock"
    cost_per_1k_tokens:
      input: 0.0
      output: 0.0
    context_window: 100000
    task_suitability:
      - "test"

  # Real models
  claude-3.5-sonnet:
    provider: "anthropic"
    cost_per_1k_tokens:
      input: 0.003
      output: 0.015
    context_window: 200000
    task_suitability:
      - "complex"
      - "coding"
  
  claude-3-opus:
    provider: "anthropic"
    cost_per_1k_tokens:
      input: 0.015
      output: 0.075
    context_window: 200000
    task_suitability:
      - "complex"
      - "reasoning"
  
  claude-3-haiku:
    provider: "anthropic"
    cost_per_1k_tokens:
      input: 0.00025
      output: 0.00125
    context_window: 200000
    task_suitability:
      - "simple"
      - "quick"

  gpt-4o:
    provider: "openai"
    cost_per_1k_tokens:
      input: 0.0025
      output: 0.01
    context_window: 128000
    task_suitability:
      - "complex"
      - "coding"
  
  gpt-4o-mini:
    provider: "openai"
    cost_per_1k_tokens:
      input: 0.00015
      output: 0.0006
    context_window: 128000
    task_suitability:
      - "simple"
      - "quick"
  
  gpt-4-turbo:
    provider: "openai"
    cost_per_1k_tokens:
      input: 0.01
      output: 0.03
    context_window: 128000
    task_suitability:
      - "complex"

# Policy Configurations
policies:
  default:
    daily_budget_usd: 100.0
    monthly_budget_usd: 3000.0
    limit:
      type: "soft"
      threshold_percent: 95
    prefer_cheaper_models_under_tokens: null
    auto_fallback_on_rate_limit: true
    log_prompts: true
    log_metadata: true
    require_justification_over_usd: null

  cost_optimization:
    simple_task_threshold_tokens: 1000
    simple_task_models:
      - "mock-model"
      - "gpt-4o-mini"
      - "claude-3-haiku"
    complex_task_models:
      - "gpt-4o"
      - "claude-3.5-sonnet"

  rate_limiting:
    max_requests_per_minute: {}
    max_requests_per_hour: {}

# Telemetry Configuration
telemetry:
  enabled: true
  db_path: "~/.llm-service/telemetry-dev.db"
  privacy_level: "full"
  retention_days: 7
