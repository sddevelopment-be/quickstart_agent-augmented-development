id: 2026-01-30T1643-adr023-phase3-context-loader
agent: backend-dev
status: assigned
priority: high
title: Implement ADR-023 Phase 3 - Progressive Context Loader with Token Counting
artefacts:
  - tools/utils/context-loader.js
  - tools/validators/agent_exports/context-loader.test.js
  - docs/HOW_TO_USE/context-optimization-guide.md
  - package.json
estimated_duration: 5-6 hours
created_at: '2026-01-30T16:43:00Z'
assigned_by: github-copilot

context_files:
  - docs/architecture/adrs/ADR-023-prompt-optimization-framework.md
  - docs/architecture/adrs/ADR-023-implementation-roadmap.md
  - docs/templates/prompts/task-execution.yaml

related_adrs:
  - ADR-023 (Prompt Optimization Framework)

directives:
  - 014 (Work Log Creation)
  - 015 (Store Prompts)
  - 016 (ATDD)
  - 017 (TDD)

depends_on:
  - 2026-01-30T1642-adr023-phase2-prompt-validator.yaml

description: |
  # Task: Implement ADR-023 Phase 3 - Progressive Context Loader with Token Counting
  
  ## Objective
  
  Implement the context optimization system for ADR-023 Phase 3, integrating tiktoken for accurate token counting and creating a progressive context loader that intelligently manages file loading within token budgets, achieving 30% token reduction (40.3K → 28K tokens average).
  
  ## Context
  
  **Background:**
  - Phase 1 created templates with context file organization (Critical/Supporting/Skip)
  - Phase 2 added validation and enforcement
  - Current state - Heavy context loading (23K-64K tokens) without budget management
  - Pattern P6 - Incomplete context loading causes token waste
  
  **Current State:**
  - Agents load all context files indiscriminately
  - No token counting or budget enforcement
  - Frequent budget overruns requiring manual intervention
  - Average 40,300 tokens per task (15,000 over target)
  
  **Target State:**
  - Accurate token counting via tiktoken
  - Progressive loading (Critical → Supporting → Skip validation)
  - Budget-aware truncation with warnings
  - Average 28,000 tokens per task (30% reduction)

deliverables:
  - file: tools/utils/context-loader.js
    type: code (Node.js module)
    validation: Exports ContextLoader class, integrates tiktoken, passes all tests
  - file: tools/validators/agent_exports/context-loader.test.js
    type: test (Jest)
    validation: 15+ tests covering budget management, truncation, edge cases, 95%+ coverage
  - file: docs/HOW_TO_USE/context-optimization-guide.md
    type: documentation
    validation: Explains token budgets, file categorization, optimization patterns with 5+ examples
  - section: package.json
    change: Add "tiktoken" dependency (version 1.0.0 or latest stable)
    type: dependency update

success_criteria:
  - Token counting accuracy within 5% of actual usage
  - Progressive loader respects budget constraints
  - Graceful handling of budget overflow (truncate or warn)
  - Test suite validates all edge cases
  - Performance - Token estimation <100ms for typical file list
  - Backward compatible with existing prompts (no breaking changes)
  - Documentation includes 5 optimization examples

constraints:
  do:
    - Use tiktoken library for token counting (GPT-4 encoding)
    - Implement progressive loading (critical first, then supporting)
    - Add budget warnings but allow override if needed
    - Follow the code structure from ADR-023 lines 574-670
    - Provide both sync and async APIs for flexibility
  dont:
    - Do not break existing prompt execution
    - Do not require all prompts to specify budgets (make it optional)
    - Do not block execution on budget violations (warn instead)
    - Do not modify template files (Phase 1 complete)
  time_box: 300 minutes (5 hours) for implementation + tests + documentation

context_loading:
  critical:
    - path: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/docs/architecture/adrs/ADR-023-prompt-optimization-framework.md
      reason: Lines 571-700 for implementation specs
    - path: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/docs/templates/prompts/task-execution.yaml
      reason: Template with token budget section
  supporting:
    - path: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/docs/architecture/adrs/ADR-023-implementation-roadmap.md
      reason: Phase 3 requirements
    - path: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/package.json
      reason: Check existing dependencies
  skip:
    - Validator implementation (separate concern)
    - CI/CD configuration
    - Historical work logs

compliance:
  directive_014: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/.github/agents/directives/014_worklog_creation.md
  directive_016: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/.github/agents/directives/016_acceptance_test_driven_development.md
  directive_017: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/.github/agents/directives/017_test_driven_development.md
  directive_023: /home/runner/work/quickstart_agent-augmented-development/quickstart_agent-augmented-development/.github/agents/directives/023_clarification_before_execution.md

mode: /analysis-mode

technical_specifications: |
  ## Context Loader Class API
  
  From ADR-023 lines 574-670:
  
  ```javascript
  class ContextLoader {
    constructor(tokenBudget = 20000)
    estimateTokens(text)
    async loadWithBudget(fileList, options = {})
    truncateToFit(content, tokenLimit)
    generateLoadReport()
  }
  ```
  
  ## Implementation Requirements
  
  1. **Token Counting Integration**
     ```javascript
     const tiktoken = require('tiktoken');
     const encoding = tiktoken.encoding_for_model('gpt-4');
     
     estimateTokens(text) {
       return encoding.encode(text).length;
     }
     ```
  
  2. **Progressive Loading Strategy**
     - Phase 1: Load all critical files (MUST fit or error)
     - Phase 2: Load supporting files (best effort within budget)
     - Phase 3: Validate skip list (ensure files not loaded)
  
  3. **Budget Management**
     - Default budget: 20,000 tokens (configurable)
     - Hard limit: 150,000 tokens (model maximum)
     - Warning threshold: 80% of budget (16,000 tokens)
  
  4. **Truncation Strategy**
     - If critical file exceeds budget, truncate intelligently:
       - Keep first 30% (context)
       - Keep last 30% (recent changes)
       - Skip middle 40% with marker
     - Preserve code structure (do not break mid-function)
  
  ## File List Format
  
  ```javascript
  {
    critical: [
      { path: '/absolute/path/to/file.js', reason: 'Contains main logic' }
    ],
    supporting: [
      { path: '/absolute/path/to/test.js', reason: 'Test cases for reference' }
    ],
    skip: [
      'historical logs',
      'archived documentation'
    ]
  }
  ```
  
  ## Load Report Format
  
  ```javascript
  {
    files: [
      { 
        path: '/path/to/file', 
        content: '...', 
        tokens: 2500, 
        truncated: false,
        reason: 'Contains interface definitions'
      }
    ],
    totalTokens: 18500,
    budget: 20000,
    utilizationPct: 92.5,
    withinBudget: true,
    warnings: []
  }
  ```
  
  ## Test Coverage Requirements
  
  15+ tests covering:
  - Token counting accuracy (compare with tiktoken directly)
  - Progressive loading (critical → supporting order)
  - Budget enforcement (stay within limits)
  - Truncation (when files exceed budget)
  - Edge cases (empty files, missing files, huge files)
  - Performance (estimation <100ms)
  - Skip list validation

checkpoints:
  - milestone: Checkpoint 1 (1.5h)
    description: Tiktoken integration and token counting working
  - milestone: Checkpoint 2 (3h)
    description: Progressive loader implementation complete
  - milestone: Checkpoint 3 (4h)
    description: Test suite complete with edge cases
  - milestone: Checkpoint 4 (5h)
    description: Documentation complete with optimization examples

handoff:
  next_agent: build-automation
  next_task_title: Update CI to check token budgets and validate context loading (ADR-023 Phase 3)
  context_to_carry_forward:
    - Context loader module location and API
    - Token budget thresholds and warnings
    - Expected usage in prompt templates
    - Integration points with existing workflow

token_budget:
  target_input: 18000
  estimated_output: 1500-2500
  description_budget: ADR + templates + minimal context for input; code + tests + docs for output

notes: |
  - Install tiktoken: `npm install tiktoken`
  - Use GPT-4 encoding (cl100k_base) for token counting
  - Consider making the loader usable both in Node.js and browser contexts
  - Provide both promise-based and callback-based APIs for flexibility
  - Token counting should cache results for repeated calls on same content
  - Document token budget recommendations by task type:
    - Simple tasks: 10K tokens
    - Medium tasks: 20K tokens
    - Complex tasks: 40K tokens
    - Architecture: 60K tokens
  
  **Assigned To:** Backend Benny  
  **Dependencies:** Phase 2 validator completion  
  **Due Date:** Phase 3 completion (4 weeks)
