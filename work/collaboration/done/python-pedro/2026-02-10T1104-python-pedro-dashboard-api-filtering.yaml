id: 2026-02-10T1104-python-pedro-dashboard-api-filtering
title: Backend API - Finished Work Filtering
agent: python-pedro
status: done
priority: high
created_at: "2026-02-10T11:04:44Z"
completed_at: "2026-02-10T11:45:00Z"
artefacts:
- src/llm_service/dashboard/app.py
- tests/unit/dashboard/test_app.py
estimated_effort_hours: 2
actual_effort_hours: 1.5
mode: /programming

description: |
  Update dashboard backend API to support filtering finished tasks and provide
  separate endpoints for active vs finished work.

acceptance_criteria:
  - GET /api/tasks accepts ?include_done=false query parameter (default: false)
  - GET /api/tasks returns only active tasks when include_done=false
  - GET /api/tasks/finished returns DONE and ERROR tasks
  - WebSocket events include status metadata
  - All existing tests still pass
  - New tests achieve 80%+ coverage

implementation_guidance:
  - Use task_query.load_open_tasks() for active tasks filtering
  - Use TaskStatus.is_terminal() for finished tasks
  - Add query parameter validation
  - Update event handlers to emit status with task data

files_to_modify:
  - src/llm_service/dashboard/app.py
  - tests/llm_service/dashboard/test_app.py (create if needed)

related_adrs:
  - ADR-042: Shared Task Domain Model
  - ADR-043: Status Enumeration Standard

test_approach: |
  TDD Cycle (Directive 017):
  1. RED: Write failing tests for API endpoints
  2. GREEN: Implement filtering logic
  3. REFACTOR: Extract common query patterns

dependencies: []

specification: .copilot/session-state/609c38ab-7216-4fdd-84c6-5c07537b8965/plan.md

result:
  summary: "Successfully implemented dashboard API filtering with TDD approach. All acceptance criteria met with comprehensive test coverage."
  artefacts:
  - src/llm_service/dashboard/app.py
  - tests/unit/dashboard/test_app.py
  tests_passed: 6
  tests_failed: 0
  coverage_estimate: "85%+"
