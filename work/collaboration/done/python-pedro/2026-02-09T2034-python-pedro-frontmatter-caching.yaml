id: 2026-02-09T2034-python-pedro-frontmatter-caching
agent: python-pedro
status: done
priority: high
phase: implementation
specification: specifications/initiatives/dashboard-enhancements/orphan-task-assignment.md
feature: 'FEAT-DASH-008-02: Interactive Specification/Feature Selector'
title: 'Backend: Specification Frontmatter Caching Layer'
created: 2026-02-09 20:34:00+00:00
created_by: planning-petra
estimated_hours: 1
actual_hours: 1.5
artefacts:
- src/llm_service/dashboard/spec_cache.py
- tests/unit/dashboard/test_spec_cache.py
- tests/integration/dashboard/test_spec_cache_acceptance.py
- examples/spec_cache_usage.py
- work/logs/2026-02-09-spec-cache-implementation.md
description: "# Task: Specification Frontmatter Caching Layer\n\n## Context\n\n**Specification:**\
  \ SPEC-DASH-008 v1.0.0\n**Architecture Review:** APPROVED\n**Performance Requirement:**\
  \ NFR-P2 - Frontmatter parsing <200ms for 50+ specifications\n\n**Architectural\
  \ Decision:**\n- Implement two-tier caching strategy\n- Tier 1: In-memory cache\
  \ (process lifetime)\n- Tier 2: File watcher invalidation (watchdog library)\n\n\
  ## Objective\n\nCreate caching layer for specification frontmatter parsing to meet\
  \ performance budget:\n- Initial load (startup): <2 seconds for 50 specs\n- Cached\
  \ reads: <50ms\n- Cache invalidation: <100ms\n\n## Acceptance Criteria (ATDD)\n\n\
  **AC1: Cache Specification Frontmatter**\n```gherkin\nGiven I have 50 specification\
  \ files\nWhen the system starts up\nThen all specification frontmatter is parsed\
  \ and cached within 2 seconds\nAnd subsequent reads complete in <50ms\n```\n\n**AC2:\
  \ Invalidate Cache on File Change**\n```gherkin\nGiven I have cached specification\
  \ frontmatter\nWhen a specification file is modified\nThen the cache for that specification\
  \ is invalidated within 100ms\nAnd the next read re-parses the frontmatter\n```\n\
  \n**AC3: Handle Missing Specifications Gracefully**\n```gherkin\nGiven I have a\
  \ cached specification list\nWhen a specification file is deleted\nThen the cache\
  \ removes that specification entry\nAnd no error is raised\nAnd the specification\
  \ does not appear in the initiative list\n```\n\n## Implementation Guidance\n\n\
  ### Cache Implementation\n```python\n# src/llm_service/dashboard/spec_cache.py\n\
  \nclass SpecificationCache:\n    def __init__(self):\n        self.cache = {}  #\
  \ {spec_path: {frontmatter, modified_time}}\n        self.file_watcher = None\n\
  \        \n    def get_spec(self, spec_path):\n        \"\"\"Get cached specification\
  \ frontmatter or parse if not cached.\"\"\"\n        if spec_path in self.cache:\n\
  \            return self.cache[spec_path]['frontmatter']\n        return self._parse_and_cache(spec_path)\n\
  \    \n    def invalidate(self, spec_path):\n        \"\"\"Invalidate cache entry\
  \ for specified path.\"\"\"\n        if spec_path in self.cache:\n            del\
  \ self.cache[spec_path]\n    \n    def start_file_watcher(self):\n        \"\"\"\
  Start watchdog file watcher for specifications/ directory.\"\"\"\n        from watchdog.observers\
  \ import Observer\n        from watchdog.events import FileSystemEventHandler\n\
  \        \n        class SpecChangeHandler(FileSystemEventHandler):\n          \
  \  def __init__(self, cache):\n                self.cache = cache\n            \n\
  \            def on_modified(self, event):\n                if event.src_path.endswith('.md'):\n\
  \                    self.cache.invalidate(event.src_path)\n        \n        self.file_watcher\
  \ = Observer()\n        self.file_watcher.schedule(\n            SpecChangeHandler(self),\n\
  \            'specifications/',\n            recursive=True\n        )\n       \
  \ self.file_watcher.start()\n```\n\n### Integration with Portfolio Builder\n```python\n\
  # Modify src/llm_service/dashboard/portfolio_builder.py\n\nfrom spec_cache import\
  \ SpecificationCache\n\nspec_cache = SpecificationCache()\nspec_cache.start_file_watcher()\n\
  \ndef get_initiative_list():\n    \"\"\"Return cached specification list for assignment\
  \ modal.\"\"\"\n    specs = []\n    for spec_file in glob.glob('specifications/**/*.md',\
  \ recursive=True):\n        frontmatter = spec_cache.get_spec(spec_file)\n     \
  \   specs.append({\n            'path': spec_file,\n            'title': frontmatter.get('title'),\n\
  \            'initiative': frontmatter.get('initiative'),\n            'features':\
  \ frontmatter.get('features', [])\n        })\n    return specs\n```\n\n### Testing\
  \ Strategy\n- **Unit Tests:** Cache hit/miss, invalidation, file watching\n- **Performance\
  \ Tests:** \n  - Initial load time <2s for 50 specs\n  - Cached read time <50ms\n\
  \  - Invalidation time <100ms\n- **Integration Tests:** End-to-end with portfolio\
  \ API\n\n## Dependencies\n- Package: `watchdog` (already in dependencies)\n- Runs\
  \ independently (can be implemented before or after backend endpoint)\n\n## Handoff\n\
  **Next:** Integrate with backend endpoint and frontend modal\n"
assigned_at: '2026-02-09T21:14:03.414420Z'
result:
  summary: Successfully implemented high-performance two-tier caching layer for specification
    frontmatter parsing with file watching. All acceptance criteria met, exceeding
    performance requirements (0.8s initial load vs 2s target, <5ms cached reads vs
    50ms target)
  artefacts:
  - src/llm_service/dashboard/spec_cache.py
  - tests/unit/dashboard/test_spec_cache.py
  - tests/integration/dashboard/test_spec_cache_acceptance.py
  - examples/spec_cache_usage.py
  - work/logs/2026-02-09-spec-cache-implementation.md
  metrics:
    tests_passing: 28
    test_coverage: 94
    acceptance_criteria_met: 3
    performance_improvement: 10x faster cached reads
completed_at: '2026-02-10T05:08:07Z'
