research-guidance.md

Research Guidance – Understanding the Experiment Outline

This document guides the researcher role in the Agentic Architecture experiment.

The researcher’s job is not to run the experiment on selected inputs.

The researcher’s job is to understand, explain, and frame the experiment itself: its intellectual roots, its underlying assumptions, its likely failure modes, and the specific concepts that must be “in the room” for the rest of the pipeline (primers → architecture → specification → execution → evaluation) to stay coherent.

Put differently:

> The researcher builds the shared mental model of the experiment.




---

Purpose of the Research Phase

The research phase exists to answer:

What is this experiment actually testing?

Which theories and concepts justify it?

Where are the sharp edges?

What must be true for it to work?

What are plausible ways it will be misused or fail?


The researcher is not responsible for:

producing a company glossary,

ingesting internal corpora,

extracting terms from transcripts,

or curating domain language in production.


That comes later, and only if the experiment proves viable.


---

What the Researcher Should Deliver

Deliverable A — Experiment Primer (Primary)

A readable primer that explains:

1. Hypothesis

Why language drift is an early signal of architectural drift.

Why DDD’s biggest corporate value is linguistic alignment.



2. Mechanism

How agentic systems change feasibility (capture, maintenance, feedback loops).

Why the system is a drift detector rather than an authority.



3. Governance

“Human in charge” as a non-negotiable accountability principle.

How contexts prevent language policing.



4. Where it fits in delivery

How research feeds primers.

How primers feed architecture.

How architecture feeds specification and execution.

How evaluation feeds capture outcomes.



5. Failure modes

Semantic policing, power capture, compliance theater.

False confidence, noisy output, glossary rot.




Deliverable B — Concept Map (Secondary)

A concept map showing how the key ideas relate:

Ubiquitous language ↔ bounded contexts ↔ translation

Conway’s Law ↔ Team Topologies ↔ cognitive load

Concept-based design ↔ OO responsibility ↔ naming as design

Architecture drift ↔ language drift ↔ coupling

Fitness functions ↔ executable constraints ↔ “linguistic checks”


Deliverable C — Annotated Reading List (Supporting)

A curated list of references with annotations answering:

Why this source matters for the experiment outline

Which sections/chapters are high value

What claims or concepts should be extracted

Where the source is prescriptive vs descriptive



---

Core Concepts the Research Must Cover

The list below is the minimum “concept inventory” required for the experiment to make sense.

1) Domain-Driven Design as Linguistic Practice

Focus: ubiquitous language, bounded contexts, translation at boundaries.

Key research questions:

Why does ubiquitous language matter more than patterns?

Why is agreement local (contextual) rather than global?

What does “translation” look like in practice (technical and social)?


Expected outputs:

a clear explanation of ubiquitous language as an operational practice,

and bounded contexts as the legitimization of disagreement.



---

2) Conway’s Law and Topological Impact

Focus: system structure reflects communication structure.

Key research questions:

How do team boundaries predict semantic boundaries?

How does misaligned topology create persistent language conflicts?

When is language drift a symptom of team design problems?


Expected outputs:

a practical explanation of Conway’s Law applied to vocabulary,

and how Team Topologies can be used to predict clashes.



---

3) Concept-Based Design and Naming as Architecture

Focus: naming is not cosmetic; it constrains design.

Key research questions:

How do concepts become stable design anchors?

What makes a concept “good enough” to build around?

How do responsibilities (OO) sharpen vocabulary?


Expected outputs:

a clear tie between concept clarity and code structure,

plus examples of how poor naming creates hidden coupling.



---

4) Agentic Systems as Feasibility Shift

Focus: what changed now vs “glossary initiatives” of the past.

Key research questions:

Why were continuous glossaries historically infeasible?

What does agentic workflow enable (capture, clustering, triage)?

Where do LLMs help (pattern detection) and where do they fail (authority)?


Expected outputs:

a sober explanation of the economics change,

and strict limits: observe + evidence, not decide.



---

5) Governance: Human in Charge

Focus: accountability and power dynamics.

Key research questions:

Who owns language decisions per context?

How do you prevent “glossary as control mechanism”?

How do you record decisions and revisit them?


Expected outputs:

governance options (lightweight to heavier),

and why “human in charge” is a design constraint.



---

6) Architectural Feedback Loops

Focus: language signals feeding architecture and review.

Key research questions:

Which linguistic signals correlate with architectural smells?

How can “linguistic checks” be advisory without becoming policing?

What belongs in PR feedback vs periodic reviews?


Expected outputs:

a mapping from language drift patterns to architecture hypotheses,

and a tiered enforcement model that defaults to advice.



---

Suggested Reference Starting Points

The researcher may draw from these sources to understand the experiment outline. The goal here is conceptual grounding, not exhaustive reading.

Domain-Driven Design / Ubiquitous Language

Eric Evans — Domain-Driven Design (ubiquitous language, bounded contexts)

Vaughn Vernon — Implementing Domain-Driven Design (boundaries and translation made concrete)

Vaughn Vernon — DDD Distilled (contrast: what simplification preserves/loses)


Conway / Team Topologies

Conway’s Law (primary sources + well-regarded summaries)

Skelton & Pais — Team Topologies (team boundaries, cognitive load)


Concept-Based Design / OO Tie-in

Responsibility-driven design (Wirfs-Brock)

Naming and communicative code (select OO design texts)


Evolution and Constraints

Ford et al. — Building Evolutionary Architectures (fitness functions; constraints over time)


DDD Crew (as contemporary vocabulary artifacts)

ddd-crew repositories (context mapping, bounded context canvas, modeling process)



---

Working Heuristics

Prefer explanations with trade-offs over prescriptions.

Separate descriptive claims (what happens) from normative claims (what should happen).

Always note where language is political and where incentives diverge.

Treat the “bot” as a sensor; keep authority and decisions human-owned.



---

Closing Reminder

This experiment stands or falls on intellectual honesty:

It must acknowledge semantic battlegrounds as normal.

It must justify bounded contexts as a way to contain conflict, not deny it.

It must keep a human in charge of meaning.


The researcher’s mission is to make that frame crisp enough that the rest of the work can proceed without drifting into theater.